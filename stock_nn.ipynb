{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngoyal16/ALGO-Trading/blob/master/stock_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Qlsq3hB-UR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1159
        },
        "outputId": "4981dc88-9b49-4121-d2d5-bec25486673e"
      },
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install pandas-datareader\n",
        "!pip install yfinance"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.14.0rc1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0rc1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.16.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (0.24.2)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.11.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2.5.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.2->pandas-datareader) (1.12.0)\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/31/14/6065cddc70cdf06dc6bb456e6636e64ededa294882e7af0dd21b3d57099f/yfinance-0.1.42.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.16.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.21.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.24->yfinance) (1.12.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/ac/b0/99fa95a2a224e0de38cd022e7d2c1d71ebce9ceabcaf4c1c11\n",
            "Successfully built yfinance\n",
            "Installing collected packages: yfinance\n",
            "Successfully installed yfinance-0.1.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGIFCi35maUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#UDACITY Learning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycD-fItsA5Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_datareader.data as pdr\n",
        "import yfinance as yf\n",
        "import time\n",
        "\n",
        "yf.pdr_override()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuYkrhHUE8Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Utility functions\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "def symbol_to_path(symbol, base_dir=\"data\"):\n",
        "  \"\"\"Return CSV File path given ticker symbol.\"\"\"\n",
        "  return os.path.join(base_dir, \"{}.csv\".format(str(symbol)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7yJRoZnBWNa",
        "colab_type": "code",
        "outputId": "8d938252-dc2f-496e-fd15-db39b7d079d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def get_stock_data(ticker, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Gets historical stock data of given tickers between dates\n",
        "    :param ticker: company, or companies whose data is to fetched\n",
        "    :type ticker: string or list of strings\n",
        "    :param start_date: starting date for stock prices\n",
        "    :type start_date: string of date \"YYYY-mm-dd\"\n",
        "    :param end_date: end date for stock prices\n",
        "    :type end_date: string of date \"YYYY-mm-dd\"\n",
        "    :return: stock_data.csv\n",
        "    \"\"\"\n",
        "    i = 1\n",
        "    try:\n",
        "        all_data = pdr.get_data_yahoo(ticker, start_date, end_date)\n",
        "    except ValueError:\n",
        "        print(\"ValueError, trying again\")\n",
        "        i += 1\n",
        "        if i < 5:\n",
        "            time.sleep(10)\n",
        "            get_stock_data(ticker, start_date, end_date)\n",
        "        else:\n",
        "            print(\"Tried 5 times, Yahoo error. Trying after 2 minutes\")\n",
        "            time.sleep(120)\n",
        "            get_stock_data(ticker, start_date, end_date)\n",
        "    stock_data = all_data[\"Adj Close\"]\n",
        "    \n",
        "    all_data.to_csv(ticker + '.csv')\n",
        "    stock_data.to_csv(\"stock_prices.csv\")\n",
        "\n",
        "\n",
        "def get_sp500(start_date, end_date):\n",
        "    \"\"\"\n",
        "    Gets sp500 price data\n",
        "    :param start_date: starting date for sp500 prices\n",
        "    :type start_date: string of date \"Y-m-d\"\n",
        "    :param end_date: end date for sp500 prices\n",
        "    :type end_date: string of date \"Y-m-d\"\n",
        "    :return: sp500_data.csv\n",
        "    \"\"\"\n",
        "    i = 1\n",
        "    try:\n",
        "        sp500_all_data = pdr.get_data_yahoo(\"SPY\", start_date, end_date)\n",
        "    except ValueError:\n",
        "        print(\"ValueError, trying again\")\n",
        "        i += 1\n",
        "        if i < 5:\n",
        "            time.sleep(10)\n",
        "            get_stock_data(start_date, end_date)\n",
        "        else:\n",
        "            print(\"Tried 5 times, Yahoo error. Trying after 2 minutes\")\n",
        "            time.sleep(120)\n",
        "            get_stock_data(start_date, end_date)\n",
        "    sp500_data = sp500_all_data[\"Adj Close\"]\n",
        "    \n",
        "    sp500_all_data.to_csv(\"sp500_all_data.csv\")\n",
        "    sp500_data.to_csv(\"sp500_data.csv\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # get_stock_data(\"AAPL\", \"2018-05-01\", \"2018-06-01\")\n",
        "    get_sp500(start_date, end_date)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZEfRzBFj24x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "symbols = ['AAPL', 'IBM', 'TATAMOTORS.NS']\n",
        "start_date  = \"2019-05-01\"\n",
        "end_date = \"2019-06-18\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mLKHfDdtQ7w",
        "colab_type": "code",
        "outputId": "e591bfb9-10d1-441d-9d7b-b2677f12cef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "for symbol in symbols:\n",
        "  get_stock_data(symbol, start_date, end_date)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 downloaded\n",
            "[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPKK9sbzkKVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyRsJPofT_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiPWUzxWt3SU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_close(symbol):\n",
        "  \"\"\"Return the maximum closing value for stock indicated by symbol.\n",
        "  \n",
        "  Note: Data for a stock is stored in file: <symbol>.csv\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(\"{}.csv\".format(symbol)) # read in data\n",
        "  return df['Close'].max() # compute and return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__EdsDe7usa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mean_volume(symbol):\n",
        "  \"\"\"Return the mean volume for stock indicated by symbol.\n",
        "  \n",
        "  Note: Data for a stock is stored in file: <symbol>.csv\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(\"{}.csv\".format(symbol)) # read in data\n",
        "  return df['Volume'].mean() # compute and return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfvH9Vwyvrf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plt_adj_close(symbol):\n",
        "  df = pd.read_csv(\"{}.csv\".format(symbol)) # read in data\n",
        "  df['Adj Close'].plot()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0BRxwKbwtmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plt_high(symbol):\n",
        "  df = pd.read_csv(\"{}.csv\".format(symbol)) # read in data\n",
        "  df['High'].plot()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHooR0w0wvC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plt_all(symbol):\n",
        "  df = pd.read_csv(\"{}.csv\".format(symbol)) # read in data\n",
        "  df[['Open', 'High', 'Low', 'Close', 'Adj Close']].plot()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vguyM7vcxG5c",
        "colab_type": "code",
        "outputId": "cf1694c5-f3b0-4a26-aab0-68e052b1f14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# Create a date range\n",
        "dates = pd.date_range(start_date, end_date)\n",
        "\n",
        "# Create an empty dataframe\n",
        "df = pd.DataFrame(index=dates)\n",
        "\n",
        "# Read SP500 data into temporary dataframe\n",
        "dfSP500 = pd.read_csv(\"sp500_all_data.csv\", \n",
        "  index_col = \"Date\", \n",
        "  parse_dates = True,\n",
        "  usecols = ['Date', 'Adj Close'],\n",
        "  na_values = ['nan']\n",
        ")\n",
        "\n",
        "# Rename VALUES column to 'SP500' to prevent clash\n",
        "dfSP500 = dfSP500.rename(columns={\n",
        "    'Adj Close': 'SP500'\n",
        "})\n",
        "\n",
        "# Join the dataframe using DataFrame Join\n",
        "df = df.join(dfSP500, how=\"inner\")\n",
        "\n",
        "for symbol in symbols:\n",
        "  # Read the `SYMBOL` data into temporary dataframe\n",
        "  df_temp = pd.read_csv('{}.csv'.format(symbol),\n",
        "    index_col = 'Date',\n",
        "    parse_dates = True,\n",
        "    usecols = ['Date', 'Adj Close'],\n",
        "    na_values = ['nan']\n",
        "  )\n",
        "  \n",
        "  # Rename VALUES column to 'SYMBOL' to prevent clash\n",
        "  df_temp = df_temp.rename(columns={\n",
        "      'Adj Close': symbol\n",
        "  })\n",
        "  \n",
        "  # Join dataframe with left join\n",
        "  df = df.join(df_temp)\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             SP500    AAPL     IBM  TATAMOTORS.NS\n",
            "2019-05-01  291.81  209.71  138.91            NaN\n",
            "2019-05-02  291.18  208.35  137.95         207.30\n",
            "2019-05-03  294.03  210.94  138.60         209.45\n",
            "2019-05-06  292.82  207.68  138.73         199.80\n",
            "2019-05-07  287.93  202.08  136.02         190.95\n",
            "2019-05-08  287.53  202.12  136.38         185.10\n",
            "2019-05-09  286.66  199.95  135.34         186.35\n",
            "2019-05-10  288.10  197.18  135.32         185.90\n",
            "2019-05-13  280.86  185.72  131.42         180.75\n",
            "2019-05-14  283.40  188.66  133.31         184.50\n",
            "2019-05-15  285.06  190.92  134.40         169.45\n",
            "2019-05-16  287.70  190.08  135.88         175.40\n",
            "2019-05-17  285.84  189.00  134.32         176.85\n",
            "2019-05-20  283.95  183.09  135.12         190.15\n",
            "2019-05-21  286.51  186.60  136.45         176.80\n",
            "2019-05-22  285.63  182.78  136.35         179.10\n",
            "2019-05-23  282.14  179.66  132.39         175.15\n",
            "2019-05-24  282.78  178.97  132.28         182.30\n",
            "2019-05-28  280.15  178.23  130.46         180.25\n",
            "2019-05-29  278.27  177.38  129.69         176.35\n",
            "2019-05-30  279.03  178.30  129.57         175.15\n",
            "2019-05-31  275.27  175.07  126.99         172.60\n",
            "2019-06-03  274.57  173.30  128.27         174.50\n",
            "2019-06-04  280.53  179.64  132.69         173.25\n",
            "2019-06-05  282.96  182.54  131.49            NaN\n",
            "2019-06-06  284.80  185.22  132.22         169.70\n",
            "2019-06-07  287.65  190.15  133.31         169.50\n",
            "2019-06-10  288.97  192.58  134.74         166.20\n",
            "2019-06-11  288.90  194.81  135.95         170.75\n",
            "2019-06-12  288.39  194.19  134.87         169.05\n",
            "2019-06-13  289.58  194.15  135.76         167.40\n",
            "2019-06-14  289.26  192.74  135.15         164.20\n",
            "2019-06-17  289.37  193.89  134.95         158.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLz_P5YxoyP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for symbol in symbols:\n",
        "  # print(\"Max close:\", symbol, get_max_close(symbol))\n",
        "  # print(\"Mean volume:\", symbol, get_mean_volume(symbol))\n",
        "  # plt_all(symbol)\n",
        "  # plt_adj_close(symbol)\n",
        "  # plt_high(symbol)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SjqNVKtC3D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5FWJQR7kOtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Asoobs-D6nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProcessing:\n",
        "    def __init__(self, file, train):\n",
        "        self.file = pd.read_csv(file)\n",
        "        self.train = train\n",
        "        self.i = int(self.train * len(self.file))\n",
        "        self.stock_train = self.file[0: self.i]\n",
        "        self.stock_test = self.file[self.i:]\n",
        "        self.input_train = []\n",
        "        self.output_train = []\n",
        "        self.input_test = []\n",
        "        self.output_test = []\n",
        "\n",
        "    def gen_train(self, seq_len):\n",
        "        \"\"\"\n",
        "        Generates training data\n",
        "        :param seq_len: length of window\n",
        "        :return: X_train and Y_train\n",
        "        \"\"\"\n",
        "        for i in range((len(self.stock_train)//seq_len)*seq_len - seq_len - 1):\n",
        "            x = np.array(self.stock_train.iloc[i: i + seq_len, 1])\n",
        "            y = np.array([self.stock_train.iloc[i + seq_len + 1, 1]], np.float64)\n",
        "            self.input_train.append(x)\n",
        "            self.output_train.append(y)\n",
        "        self.X_train = np.array(self.input_train)\n",
        "        self.Y_train = np.array(self.output_train)\n",
        "\n",
        "    def gen_test(self, seq_len):\n",
        "        \"\"\"\n",
        "        Generates test data\n",
        "        :param seq_len: Length of window\n",
        "        :return: X_test and Y_test\n",
        "        \"\"\"\n",
        "        for i in range((len(self.stock_test)//seq_len)*seq_len - seq_len - 1):\n",
        "            x = np.array(self.stock_test.iloc[i: i + seq_len, 1])\n",
        "            y = np.array([self.stock_test.iloc[i + seq_len + 1, 1]], np.float64)\n",
        "            self.input_test.append(x)\n",
        "            self.output_test.append(y)\n",
        "        self.X_test = np.array(self.input_test)\n",
        "        self.Y_test = np.array(self.output_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo7siaWdJzhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_test(strategy, seq_len, ticker, start_date, end_date, dim):\n",
        "    \"\"\"\n",
        "    A simple back test for a given date period\n",
        "    :param strategy: the chosen strategy. Note to have already formed the model, and fitted with training data.\n",
        "    :param seq_len: length of the days used for prediction\n",
        "    :param ticker: company ticker\n",
        "    :param start_date: starting date\n",
        "    :type start_date: \"YYYY-mm-dd\"\n",
        "    :param end_date: ending date\n",
        "    :type end_date: \"YYYY-mm-dd\"\n",
        "    :param dim: dimension required for strategy: 3dim for LSTM and 2dim for MLP\n",
        "    :type dim: tuple\n",
        "    :return: Percentage errors array that gives the errors for every test in the given date range\n",
        "    \"\"\"\n",
        "    data = pdr.get_data_yahoo(ticker, start_date, end_date)\n",
        "    stock_data = data[\"Adj Close\"]\n",
        "    errors = []\n",
        "    \n",
        "    for i in range((len(stock_data)//10)*10 - seq_len - 1):\n",
        "        x = np.array(stock_data.iloc[i: i + seq_len]).reshape(dim) / 200\n",
        "        y = np.array(stock_data.iloc[i + seq_len + 1]) / 200\n",
        "        predict = strategy.predict(x)\n",
        "        while predict == 0:\n",
        "            predict = strategy.predict(x)\n",
        "        error = (predict - y) / 100\n",
        "        errors.append(error)\n",
        "    total_error = np.array(errors)\n",
        "    print(f\"Average error = {total_error.mean()}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5iTiZ2XDxcY",
        "colab_type": "code",
        "outputId": "06baa5e8-fb76-493a-9ae9-05397ec7cc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "start_date = \"2003-01-01\"\n",
        "end_date = \"2019-01-01\"\n",
        "get_stock_data(\"AAPL\", start_date=start_date, end_date=end_date)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg66Yg1JEgF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "process = DataProcessing(\"stock_prices.csv\", 0.9)\n",
        "process.gen_test(10)\n",
        "process.gen_train(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNw9DTbyLMLo",
        "colab_type": "code",
        "outputId": "823028d0-559e-4e5f-d80f-b20ac59663d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(process.X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3609"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvO6X2xiLj2p",
        "colab_type": "code",
        "outputId": "32ab5f2c-0744-4161-9953-27aa7ab41aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(process.X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "389"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrsZr017El0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = process.X_train.reshape((3609, 10, 1)) / 200\n",
        "Y_train = process.Y_train / 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eee6oyNGExpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = process.X_test.reshape(389, 10, 1) / 200\n",
        "Y_test = process.Y_test / 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jDbrsdUE1En",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(20, input_shape=(10, 1), return_sequences=True))\n",
        "model.add(tf.keras.layers.LSTM(20))\n",
        "model.add(tf.keras.layers.Dense(1, activation=tf.nn.relu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJIjL-z0Lnnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kwz8SpFE6JX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5BtzSorE83R",
        "colab_type": "code",
        "outputId": "8546768a-994c-4f0d-9a66-6914a1e322f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3609/3609 [==============================] - 3s 896us/sample - loss: 0.0783\n",
            "Epoch 2/50\n",
            "3609/3609 [==============================] - 2s 434us/sample - loss: 0.0783\n",
            "Epoch 3/50\n",
            "3609/3609 [==============================] - 2s 451us/sample - loss: 0.0783\n",
            "Epoch 4/50\n",
            "3609/3609 [==============================] - 2s 439us/sample - loss: 0.0783\n",
            "Epoch 5/50\n",
            "3609/3609 [==============================] - 2s 433us/sample - loss: 0.0783\n",
            "Epoch 6/50\n",
            "3609/3609 [==============================] - 2s 438us/sample - loss: 0.0783\n",
            "Epoch 7/50\n",
            "3609/3609 [==============================] - 2s 441us/sample - loss: 0.0783\n",
            "Epoch 8/50\n",
            "3609/3609 [==============================] - 2s 451us/sample - loss: 0.0783\n",
            "Epoch 9/50\n",
            "3609/3609 [==============================] - 2s 444us/sample - loss: 0.0783\n",
            "Epoch 10/50\n",
            "3609/3609 [==============================] - 2s 444us/sample - loss: 0.0783\n",
            "Epoch 11/50\n",
            "3609/3609 [==============================] - 2s 443us/sample - loss: 0.0783\n",
            "Epoch 12/50\n",
            "3609/3609 [==============================] - 2s 443us/sample - loss: 0.0783\n",
            "Epoch 13/50\n",
            "3609/3609 [==============================] - 2s 441us/sample - loss: 0.0783\n",
            "Epoch 14/50\n",
            "3609/3609 [==============================] - 2s 439us/sample - loss: 0.0783\n",
            "Epoch 15/50\n",
            "3609/3609 [==============================] - 2s 449us/sample - loss: 0.0783\n",
            "Epoch 16/50\n",
            "3609/3609 [==============================] - 2s 462us/sample - loss: 0.0783\n",
            "Epoch 17/50\n",
            "3609/3609 [==============================] - 2s 456us/sample - loss: 0.0783\n",
            "Epoch 18/50\n",
            "3609/3609 [==============================] - 2s 449us/sample - loss: 0.0783\n",
            "Epoch 19/50\n",
            "3609/3609 [==============================] - 2s 459us/sample - loss: 0.0783\n",
            "Epoch 20/50\n",
            "3609/3609 [==============================] - 2s 455us/sample - loss: 0.0783\n",
            "Epoch 21/50\n",
            "3609/3609 [==============================] - 2s 451us/sample - loss: 0.0783\n",
            "Epoch 22/50\n",
            "3609/3609 [==============================] - 2s 456us/sample - loss: 0.0783\n",
            "Epoch 23/50\n",
            "3609/3609 [==============================] - 2s 462us/sample - loss: 0.0783\n",
            "Epoch 24/50\n",
            "3609/3609 [==============================] - 2s 460us/sample - loss: 0.0783\n",
            "Epoch 25/50\n",
            "3609/3609 [==============================] - 2s 458us/sample - loss: 0.0783\n",
            "Epoch 26/50\n",
            "3609/3609 [==============================] - 2s 456us/sample - loss: 0.0783\n",
            "Epoch 27/50\n",
            "3609/3609 [==============================] - 2s 461us/sample - loss: 0.0783\n",
            "Epoch 28/50\n",
            "3609/3609 [==============================] - 2s 450us/sample - loss: 0.0783\n",
            "Epoch 29/50\n",
            "3609/3609 [==============================] - 2s 464us/sample - loss: 0.0783\n",
            "Epoch 30/50\n",
            "3609/3609 [==============================] - 2s 447us/sample - loss: 0.0783\n",
            "Epoch 31/50\n",
            "3609/3609 [==============================] - 2s 451us/sample - loss: 0.0783\n",
            "Epoch 32/50\n",
            "3609/3609 [==============================] - 2s 446us/sample - loss: 0.0783\n",
            "Epoch 33/50\n",
            "3609/3609 [==============================] - 2s 452us/sample - loss: 0.0783\n",
            "Epoch 34/50\n",
            "3609/3609 [==============================] - 2s 470us/sample - loss: 0.0783\n",
            "Epoch 35/50\n",
            "3609/3609 [==============================] - 2s 469us/sample - loss: 0.0783\n",
            "Epoch 36/50\n",
            "3609/3609 [==============================] - 2s 465us/sample - loss: 0.0783\n",
            "Epoch 37/50\n",
            "3609/3609 [==============================] - 2s 454us/sample - loss: 0.0783\n",
            "Epoch 38/50\n",
            "3609/3609 [==============================] - 2s 456us/sample - loss: 0.0783\n",
            "Epoch 39/50\n",
            "3609/3609 [==============================] - 2s 453us/sample - loss: 0.0783\n",
            "Epoch 40/50\n",
            "3609/3609 [==============================] - 2s 453us/sample - loss: 0.0783\n",
            "Epoch 41/50\n",
            "3609/3609 [==============================] - 2s 455us/sample - loss: 0.0783\n",
            "Epoch 42/50\n",
            "3609/3609 [==============================] - 2s 458us/sample - loss: 0.0783\n",
            "Epoch 43/50\n",
            "3609/3609 [==============================] - 2s 456us/sample - loss: 0.0783\n",
            "Epoch 44/50\n",
            "3609/3609 [==============================] - 2s 463us/sample - loss: 0.0783\n",
            "Epoch 45/50\n",
            "3609/3609 [==============================] - 2s 453us/sample - loss: 0.0783\n",
            "Epoch 46/50\n",
            "3609/3609 [==============================] - 2s 460us/sample - loss: 0.0783\n",
            "Epoch 47/50\n",
            "3609/3609 [==============================] - 2s 462us/sample - loss: 0.0783\n",
            "Epoch 48/50\n",
            "3609/3609 [==============================] - 2s 472us/sample - loss: 0.0783\n",
            "Epoch 49/50\n",
            "3609/3609 [==============================] - 2s 462us/sample - loss: 0.0783\n",
            "Epoch 50/50\n",
            "3609/3609 [==============================] - 2s 461us/sample - loss: 0.0783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2917a1898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ_CmZXmFIMZ",
        "colab_type": "code",
        "outputId": "a685a663-f73e-4505-a25c-805568580fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(model.evaluate(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "389/389 [==============================] - 0s 976us/sample - loss: 0.7812\n",
            "0.7811904324357491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvBszObbFNpQ",
        "colab_type": "code",
        "outputId": "85ae1fa3-6cfc-4fe4-d910-166ebc5db368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data = pdr.get_data_yahoo(\"AAPL\", \"2018-12-19\", \"2019-01-04\")\n",
        "stock = data[\"Adj Close\"]\n",
        "X_predict = np.array(stock).reshape((1, 10, 1)) / 200\n",
        "print(model.predict(X_predict)*200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n",
            "[[0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ4P_NBfFYAI",
        "colab_type": "code",
        "outputId": "acd9cba7-bf61-4268-b9d1-3d865dcbf066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgLop4gFIV7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZOLwHcDIV-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK5Y0JnYIWBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIgaSOx9IWFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOSLmUaRIWH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = process.X_train / 200\n",
        "Y_train = process.Y_train / 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W75MoLTxIXLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = process.X_test / 200\n",
        "Y_test = process.Y_test / 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVXAFrRKIYsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(1, activation=tf.nn.relu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm_H_r76Iap4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey5mjgUNIcQw",
        "colab_type": "code",
        "outputId": "4cb08929-3f1d-4a0d-d5a8-f6b12305460f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3094
        }
      },
      "source": [
        "model.fit(X_train, Y_train, epochs=90)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.5011e-05\n",
            "Epoch 2/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.1233e-05\n",
            "Epoch 3/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.7044e-05\n",
            "Epoch 4/90\n",
            "3609/3609 [==============================] - 0s 57us/sample - loss: 4.8345e-05\n",
            "Epoch 5/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.5696e-05\n",
            "Epoch 6/90\n",
            "3609/3609 [==============================] - 0s 55us/sample - loss: 4.1767e-05\n",
            "Epoch 7/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.2607e-05\n",
            "Epoch 8/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.4895e-05\n",
            "Epoch 9/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.1694e-05\n",
            "Epoch 10/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.4044e-05\n",
            "Epoch 11/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.0458e-05\n",
            "Epoch 12/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.4861e-05\n",
            "Epoch 13/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 3.9635e-05\n",
            "Epoch 14/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.2973e-05\n",
            "Epoch 15/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.3744e-05\n",
            "Epoch 16/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.9010e-05\n",
            "Epoch 17/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.7032e-05\n",
            "Epoch 18/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.1765e-05\n",
            "Epoch 19/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.0775e-05\n",
            "Epoch 20/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.2858e-05\n",
            "Epoch 21/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3441e-05\n",
            "Epoch 22/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.7937e-05\n",
            "Epoch 23/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.5175e-05\n",
            "Epoch 24/90\n",
            "3609/3609 [==============================] - 0s 55us/sample - loss: 4.0588e-05\n",
            "Epoch 25/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.2543e-05\n",
            "Epoch 26/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.2630e-05\n",
            "Epoch 27/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.6474e-05\n",
            "Epoch 28/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 5.1592e-05\n",
            "Epoch 29/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.7921e-05\n",
            "Epoch 30/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.1387e-05\n",
            "Epoch 31/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.1102e-05\n",
            "Epoch 32/90\n",
            "3609/3609 [==============================] - 0s 57us/sample - loss: 4.8785e-05\n",
            "Epoch 33/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.4881e-05\n",
            "Epoch 34/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.7411e-05\n",
            "Epoch 35/90\n",
            "3609/3609 [==============================] - 0s 62us/sample - loss: 4.8495e-05\n",
            "Epoch 36/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.4643e-05\n",
            "Epoch 37/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.8663e-05\n",
            "Epoch 38/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.2639e-05\n",
            "Epoch 39/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 5.0059e-05\n",
            "Epoch 40/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.2740e-05\n",
            "Epoch 41/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.9854e-05\n",
            "Epoch 42/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.1700e-05\n",
            "Epoch 43/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.3698e-05\n",
            "Epoch 44/90\n",
            "3609/3609 [==============================] - 0s 55us/sample - loss: 4.4039e-05\n",
            "Epoch 45/90\n",
            "3609/3609 [==============================] - 0s 55us/sample - loss: 4.3645e-05\n",
            "Epoch 46/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.3511e-05\n",
            "Epoch 47/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.2918e-05\n",
            "Epoch 48/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.3050e-05\n",
            "Epoch 49/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.0774e-05\n",
            "Epoch 50/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.1579e-05\n",
            "Epoch 51/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.2899e-05\n",
            "Epoch 52/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.7804e-05\n",
            "Epoch 53/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.1471e-05\n",
            "Epoch 54/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.5728e-05\n",
            "Epoch 55/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.2976e-05\n",
            "Epoch 56/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.5729e-05\n",
            "Epoch 57/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.8894e-05\n",
            "Epoch 58/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3299e-05\n",
            "Epoch 59/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.4082e-05\n",
            "Epoch 60/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.8068e-05\n",
            "Epoch 61/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.5558e-05\n",
            "Epoch 62/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3364e-05\n",
            "Epoch 63/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.5821e-05\n",
            "Epoch 64/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3112e-05\n",
            "Epoch 65/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.9480e-05\n",
            "Epoch 66/90\n",
            "3609/3609 [==============================] - 0s 54us/sample - loss: 4.1645e-05\n",
            "Epoch 67/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3071e-05\n",
            "Epoch 68/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.4878e-05\n",
            "Epoch 69/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.4711e-05\n",
            "Epoch 70/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.1585e-05\n",
            "Epoch 71/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.0948e-05\n",
            "Epoch 72/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.2720e-05\n",
            "Epoch 73/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.1211e-05\n",
            "Epoch 74/90\n",
            "3609/3609 [==============================] - 0s 50us/sample - loss: 4.2817e-05\n",
            "Epoch 75/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.0721e-05\n",
            "Epoch 76/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.2666e-05\n",
            "Epoch 77/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3095e-05\n",
            "Epoch 78/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.1472e-05\n",
            "Epoch 79/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.9267e-05\n",
            "Epoch 80/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 5.1304e-05\n",
            "Epoch 81/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.8545e-05\n",
            "Epoch 82/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.2078e-05\n",
            "Epoch 83/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3623e-05\n",
            "Epoch 84/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.0099e-05\n",
            "Epoch 85/90\n",
            "3609/3609 [==============================] - 0s 53us/sample - loss: 4.1853e-05\n",
            "Epoch 86/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.2954e-05\n",
            "Epoch 87/90\n",
            "3609/3609 [==============================] - 0s 51us/sample - loss: 4.3099e-05\n",
            "Epoch 88/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.3193e-05\n",
            "Epoch 89/90\n",
            "3609/3609 [==============================] - 0s 56us/sample - loss: 4.0799e-05\n",
            "Epoch 90/90\n",
            "3609/3609 [==============================] - 0s 52us/sample - loss: 4.1616e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe291361e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOkZ7e6iIi7B",
        "colab_type": "code",
        "outputId": "67a5f28a-346c-4dec-d9b6-7cea51b2ad88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(model.evaluate(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "389/389 [==============================] - 0s 56us/sample - loss: 6.2063e-04\n",
            "0.0006206300412484261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-2t1hRsIn4X",
        "colab_type": "code",
        "outputId": "ab94cfac-e9da-4cad-9ff9-5e73753600e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data = pdr.get_data_yahoo(\"AAPL\", \"2019-01-02\", \"2019-01-16\")\n",
        "stock = data[\"Adj Close\"]\n",
        "X_predict = np.array(stock).reshape((1, 10)) / 200\n",
        "print(model.predict(X_predict)*200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n",
            "[[154.00316]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lAM5h7PPv7n",
        "colab_type": "code",
        "outputId": "dba2f565-7528-4c4c-eeed-2a60ffb84344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "back_test(strategy=model, seq_len=10, ticker='AAPL', start_date=start_date, end_date=end_date, dim=(1, 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n",
            "Average error = -1.8484941392671317e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBqhxj_zgELQ",
        "colab_type": "code",
        "outputId": "111d65ea-3da6-44df-ef0b-1af16545aad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "back_test(strategy=model, seq_len=10, ticker='AAPL', start_date=start_date, end_date=end_date, dim=(1, 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 downloaded\n",
            "Average error = 4.990389061276801e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z0x46stjFR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkbDll0bjFYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzo8OmPzjFcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imHTgf9_jFfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiQloZvCjFjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN4rKmTrjFms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nw_Szp5jFpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE5UuiT4jFtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxWbpDhbjFVm",
        "colab_type": "code",
        "outputId": "4e3fc367-cf4b-4cad-d845-ef1b0e31c17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "import calendar\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import groupby\n",
        "\n",
        "TYPE_LINE_UNDEFINED = 0\n",
        "TYPE_LINE_BOOK_DATA_STK = 1\n",
        "TYPE_LINE_BOOK_DATA_FUT = 2\n",
        "TYPE_LINE_BOOK_OPTION = 3\n",
        "TYPE_LINE_TRADED_VOLUME = 4\n",
        "\n",
        "def checkDate(lineItem):\n",
        "    try:\n",
        "        datetime.strptime(lineItem, '%Y/%m/%d')\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def checkTimestamp(lineItem):\n",
        "    return True\n",
        "\n",
        "\n",
        "# Returns the type of lineItems\n",
        "def validateLineItem(lineItems):\n",
        "    if len(lineItems) < 4:\n",
        "        return TYPE_LINE_UNDEFINED\n",
        "    if checkDate(lineItems[0]) and checkTimestamp(lineItems[1]) and lineItems[2] == \"Book\":\n",
        "        if lineItems[4][-3:] == \"-10\":\n",
        "            return TYPE_LINE_BOOK_DATA_FUT\n",
        "        else:\n",
        "            return TYPE_LINE_BOOK_DATA_STK\n",
        "    if len(lineItems) == 7 and lineItems[3] == '|':\n",
        "        return TYPE_LINE_BOOK_OPTION\n",
        "    if checkDate(lineItems[0]) and checkTimestamp(lineItems[1]) and lineItems[2] == \"TradeInfo\":\n",
        "        return TYPE_LINE_TRADED_VOLUME\n",
        "    return TYPE_LINE_UNDEFINED\n",
        "\n",
        "def parseBookDataOptionLine(lineItems):\n",
        "    if (len(lineItems) < 7):\n",
        "        return None\n",
        "    bidVol = float(lineItems[1])\n",
        "    bidPrice = float(lineItems[2])\n",
        "    askPrice = float(lineItems[4])\n",
        "    askVol = float(lineItems[5])\n",
        "    return {'bidVolume': bidVol,\n",
        "            'bidPrice': bidPrice,\n",
        "            'askPrice': askPrice,\n",
        "            'askVolume': askVol}\n",
        "\n",
        "\n",
        "def get_exp_date(trade_date, holiday_dates):\n",
        "    date = max(week[-4] for week in calendar.monthcalendar(trade_date.year, trade_date.month))\n",
        "    if date >= trade_date.day:\n",
        "        exp_date = datetime(year=trade_date.year, month=trade_date.month, day=date)\n",
        "    else:\n",
        "        if trade_date.month != 12:\n",
        "            date = max(week[-4] for week in calendar.monthcalendar(trade_date.year, 1 + trade_date.month))\n",
        "            exp_date = datetime(year=trade_date.year, month=1 + trade_date.month, day=date)\n",
        "        else:\n",
        "            date = max(week[-4] for week in calendar.monthcalendar(1 + trade_date.year, 1))\n",
        "            exp_date = datetime(year=1 + trade_date.year, month=1, day=date)\n",
        "    if datetime.strftime(exp_date, '%Y%m%d') in holiday_dates:\n",
        "        exp_date = exp_date + timedelta(days=-1)\n",
        "    return exp_date.replace(hour=15, minute=30)\n",
        "\n",
        "def groupAndSortByTimeUpdates(instrumentUpdates):\n",
        "    instrumentUpdates.sort(key=lambda x: x['timeOfUpdate'])\n",
        "    groupedInstruments = []\n",
        "    # groupby only works on already sorted elements, so we sorted first\n",
        "    for timeOfUpdate, sameTimeInstruments in groupby(instrumentUpdates, lambda x: x['timeOfUpdate']):\n",
        "        instruments = []\n",
        "        for sameTimeInstrument in sameTimeInstruments:\n",
        "            instruments.append(sameTimeInstrument)\n",
        "        groupedInstruments.append([timeOfUpdate, instruments])\n",
        "    return groupedInstruments\n",
        "\n",
        "class InstrumentsFromFile():\n",
        "    def __init__(self, fileName, expiryTime):\n",
        "        self.fileName = fileName\n",
        "        self.expiryTime = expiryTime\n",
        "        self.currentInstrumentSymbol = None\n",
        "        self.currentTimeOfUpdate = None\n",
        "        self.currentBookData = None\n",
        "        self.currentFutureBookData = None\n",
        "        self.futureFlag = False\n",
        "\n",
        "    def processLine(self, line):\n",
        "        lineItems = line.split()\n",
        "        lineItemType = validateLineItem(lineItems)\n",
        "        if (lineItemType == TYPE_LINE_BOOK_DATA_STK):\n",
        "            inst = None\n",
        "            if self.currentInstrumentSymbol is not None:\n",
        "                inst = {'stockInstrumentId' : self.currentInstrumentSymbol,\n",
        "                        'tradeSymbol' : self.currentInstrumentSymbol,\n",
        "                        'timeOfUpdate' : self.currentTimeOfUpdate,\n",
        "                        'bookData' : self.currentBookData,\n",
        "                        'expiryTime' : self.expiryTime,\n",
        "                        'futureBookData' : self.currentFutureBookData}\n",
        "            self.currentTimeOfUpdate = datetime.strptime(lineItems[0] + ' ' + lineItems[1], \"%Y/%m/%d %H:%M:%S:%f\")\n",
        "            self.currentInstrumentSymbol = lineItems[4]\n",
        "            self.currentBookData = None\n",
        "            self.currentFutureBookData = None\n",
        "            self.futureFlag = False\n",
        "            return inst\n",
        "        elif(lineItemType == TYPE_LINE_BOOK_OPTION):\n",
        "            parsedOption = parseBookDataOptionLine(lineItems)\n",
        "            if not self.futureFlag:\n",
        "                if self.currentBookData is None:\n",
        "                    self.currentBookData = {}\n",
        "                    self.currentBookData['bidVolume'] = np.array([parsedOption['bidVolume']])\n",
        "                    self.currentBookData['bidPrice'] = np.array([parsedOption['bidPrice']])\n",
        "                    self.currentBookData['askPrice'] = np.array([parsedOption['askPrice']])\n",
        "                    self.currentBookData['askVolume'] = np.array([parsedOption['askVolume']])\n",
        "                else:\n",
        "                    self.currentBookData['bidVolume'] = np.append(self.currentBookData['bidVolume'], parsedOption['bidVolume'])\n",
        "                    self.currentBookData['bidPrice'] = np.append(self.currentBookData['bidPrice'], parsedOption['bidPrice'])\n",
        "                    self.currentBookData['askPrice'] = np.append(self.currentBookData['askPrice'], parsedOption['askPrice'])\n",
        "                    self.currentBookData['askVolume'] = np.append(self.currentBookData['askVolume'], parsedOption['askVolume'])\n",
        "            else:\n",
        "                if self.currentFutureBookData is None:\n",
        "                    self.currentFutureBookData = {}\n",
        "                    self.currentFutureBookData['bidVolume'] = np.array([parsedOption['bidVolume']])\n",
        "                    self.currentFutureBookData['bidPrice'] = np.array([parsedOption['bidPrice']])\n",
        "                    self.currentFutureBookData['askPrice'] = np.array([parsedOption['askPrice']])\n",
        "                    self.currentFutureBookData['askVolume'] = np.array([parsedOption['askVolume']])\n",
        "                else:\n",
        "                    self.currentFutureBookData['bidVolume'] = np.append(self.currentFutureBookData['bidVolume'], parsedOption['bidVolume'])\n",
        "                    self.currentFutureBookData['bidPrice'] = np.append(self.currentFutureBookData['bidPrice'], parsedOption['bidPrice'])\n",
        "                    self.currentFutureBookData['askPrice'] = np.append(self.currentFutureBookData['askPrice'], parsedOption['askPrice'])\n",
        "                    self.currentFutureBookData['askVolume'] = np.append(self.currentFutureBookData['askVolume'], parsedOption['askVolume'])\n",
        "        elif(lineItemType == TYPE_LINE_TRADED_VOLUME):\n",
        "            if not self.futureFlag:\n",
        "                self.currentBookData['total_traded_value'] = lineItems[6]\n",
        "                self.currentBookData['total_traded_size'] = lineItems[8]\n",
        "            else:\n",
        "                self.currentFutureBookData['total_traded_value'] = lineItems[6]\n",
        "                self.currentFutureBookData['total_traded_size'] = lineItems[8]\n",
        "        elif(lineItemType == TYPE_LINE_BOOK_DATA_FUT):\n",
        "            self.futureFlag = True\n",
        "\n",
        "    def processLinesIntoInstruments(self):\n",
        "        with open(self.fileName, \"r\") as ins:\n",
        "            instruments = []\n",
        "            for line in ins:\n",
        "                inst = self.processLine(line)\n",
        "                if inst is not None:\n",
        "                    instruments.append(inst)\n",
        "            return instruments\n",
        "\n",
        "\n",
        "class DataSource(object):\n",
        "    def __init__(self, folderName, instrumentIds, startDateStr, endDateStr):\n",
        "        self.startDate = datetime.strptime(startDateStr, \"%Y%m%d\")\n",
        "        self.endDate = datetime.strptime(endDateStr, \"%Y%m%d\")\n",
        "        self.folderName = folderName\n",
        "        self.instrumentIds = instrumentIds\n",
        "        self.currentDate = self.startDate\n",
        "\n",
        "    def getFileName(self, date):\n",
        "        dateStr = date.strftime(\"%Y%m%d\")\n",
        "        return '%s/%s/data' % (self.folderName, dateStr)\n",
        "\n",
        "    def emitInstrumentUpdate(self, holidays):\n",
        "        while (self.currentDate <= self.endDate):\n",
        "            allInstrumentUpdates = []\n",
        "            fileName = self.getFileName(self.currentDate)\n",
        "            if not os.path.isfile(fileName):\n",
        "                continue\n",
        "            expiryTime = get_exp_date(self.currentDate, holidays)\n",
        "            fileHandler = InstrumentsFromFile(fileName=fileName, expiryTime=expiryTime)\n",
        "            instrumentUpdates = fileHandler.processLinesIntoInstruments()\n",
        "            allInstrumentUpdates = allInstrumentUpdates + instrumentUpdates\n",
        "            groupedInstrumentUpdates = groupAndSortByTimeUpdates(allInstrumentUpdates)\n",
        "            for timeOfUpdate, instrumentUpdates in groupedInstrumentUpdates:\n",
        "                yield([timeOfUpdate, instrumentUpdates])\n",
        "            self.currentDate = self.currentDate + timedelta(days=1)\n",
        "\n",
        "\n",
        "def getvwap(stockData):\n",
        "    bid_vol, ask_vol, bid_price, ask_price = stockData['bidVolume'], stockData['askVolume'], stockData['bidPrice'], stockData['askPrice']\n",
        "    volume = (np.sum(bid_vol) + np.sum(ask_vol))\n",
        "    if volume > 0:\n",
        "        price = (np.sum(bid_price * ask_vol) + np.sum(ask_price * bid_vol)) / (volume)  # Calculated for a vol = 0.12353\n",
        "    else:\n",
        "        price = (np.sum(bid_price) + np.sum(ask_price)) / (len(bid_price))\n",
        "    return price\n",
        "\n",
        "def getbidp(stockData):\n",
        "    bid_price=stockData['bidPrice']\n",
        "    return np.max(bid_price)\n",
        "\n",
        "def getaskp(stockData):\n",
        "    ask_price=stockData['askPrice']\n",
        "    return np.max(ask_price)\n",
        "\n",
        "def get_totalv(stockData):\n",
        "    total_value=stockData['total_traded_value']\n",
        "    return total_value\n",
        "    #print(total_value)\n",
        "\n",
        "def get_totals(stockData):\n",
        "    total_size=stockData['total_traded_size']\n",
        "    return total_size\n",
        "\n",
        "\n",
        "\n",
        "def writecsv(csv_dir, results, m):\n",
        "    # results = results.sort_index(axis=0, ascending=False)\n",
        "    print('writing %s%s.csv' % (csv_dir, m))\n",
        "    fileName = '%s%s.csv' % (csv_dir, m)\n",
        "    if os.path.exists(fileName):\n",
        "        csv_file = open(fileName, 'a')\n",
        "        results.to_csv(csv_file, header=False)\n",
        "    else:\n",
        "        csv_file = open(fileName, 'w ')\n",
        "        results.to_csv(csv_file, header=True)\n",
        "    csv_file.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    folderName = 'spare/local/cjain/NSEDATA/'\n",
        "    fileName = 'stocklist'\n",
        "    holiday_dates = ['20160706', '20160815', '20160905', '20160913', '20161011', '20161012', '20161031', '20161114', \n",
        "                '20161225', '20170101', '20170126', '20170224', '20170313', '20170404', '20170414', '20170501',\n",
        "                '20170626', '20170815', '20170825', '20171002', '20171019', '20171020', '20171225', \n",
        "                '20180101', '20180126', '20180213', '20180302', '20180329', '20180330', '20180501', \n",
        "                '20180815', '20180822', '20180913', '20180920', '20181002', '20181018', '20181107', '20181225']\n",
        "\n",
        "    dates =  next(os.walk(folderName))[1]\n",
        "    dates.sort()\n",
        "    print(dates)\n",
        "    instrumentIds = []\n",
        "    with open(fileName, \"r\") as f:\n",
        "        for line in f:\n",
        "            lineItems = line.split()\n",
        "            instrumentIds.append(lineItems[0])\n",
        "\n",
        "    for date in dates:\n",
        "        all_data = {}\n",
        "        startDateStr = date\n",
        "        endDateStr = date\n",
        "        for instrumentId in instrumentIds:\n",
        "            all_data[instrumentId] = pd.DataFrame(index=[pd.date_range(startDateStr + ' 09:16:00', periods=375, freq='60s')],\n",
        "                                                  columns=['stockVWAP', 'futureVWAP','bidPrice','askPrice', 'total_size', 'total_value'])\n",
        "\n",
        "        dataParser = DataSource(folderName, instrumentIds, startDateStr, endDateStr)\n",
        "        groupedInstrumentUpdates = dataParser.emitInstrumentUpdate(holiday_dates)\n",
        "        for timeOfUpdate, instrumentUpdates in groupedInstrumentUpdates:\n",
        "            print(timeOfUpdate)\n",
        "            for instrumentUpdate in instrumentUpdates:\n",
        "                instrumentId = instrumentUpdate['tradeSymbol']\n",
        "                if timeOfUpdate in all_data[instrumentId].index:\n",
        "                    stockData = instrumentUpdate['bookData']\n",
        "                    futureData = instrumentUpdate['futureBookData']\n",
        "                    stockData['bidPrice'] = stockData['bidPrice'] / 100.0\n",
        "                    stockData['askPrice'] = stockData['askPrice'] / 100.0\n",
        "                    futureData['bidPrice'] = futureData['bidPrice'] / 100.0\n",
        "                    futureData['askPrice'] = futureData['askPrice'] / 100.0\n",
        "                    all_data[instrumentId].loc[timeOfUpdate, 'stockVWAP'] = getvwap(stockData)\n",
        "                    all_data[instrumentId].loc[timeOfUpdate, 'futureVWAP'] = getvwap(futureData)\n",
        "                    all_data[instrumentId].loc[timeOfUpdate, 'bidPrice'] = getbidp(stockData)\n",
        "                    all_data[instrumentId].loc[timeOfUpdate, 'askPrice'] = getaskp(stockData)\n",
        "                    all_data[instrumentId].loc[timeOfUpdate, 'total_value'] = get_totalv(stockData)\n",
        "                    all_data[instrumentId].loc[timeOfUpdate, 'total_size'] = get_totals(stockData)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for instrumentId in instrumentIds:\n",
        "            writecsv('stock_data_new/', all_data[instrumentId], instrumentId)\n",
        "            #writecsv('parsedData/', futureData['askPrice'], instrumentId)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-2c6131633f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m                 '20180815', '20180822', '20180913', '20180920', '20181002', '20181018', '20181107', '20181225']\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    }
  ]
}